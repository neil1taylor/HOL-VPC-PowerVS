# Hands-on Lab 6: Configuring Observability services to monitor IBM Cloud, VPC and PowerVS

## Objective

Learn how to configure and manage Observability services to monitor your workloads, focusing on IBM Cloud VPC and IBM Power Virtual Server.

What you will learn:

- Configure IBM Cloud Observability services in an IBM Cloud account
- Core features in IBM Cloud Logs
- Monitoring IBM Cloud VPC using IBM Cloud Logs
- Building views and dashboards, configuring alerts for automated incident response.
- Configuring PowerVS to send logs to IBM Cloud Logs and metrics to IBM Cloud Monitoring
- Integrating third-party observability tools with IBM Cloud.


## Overview

Cloud governance is a framework of guidelines, policies, and practices that help standardize the adoption and management of cloud services securely, mitigate risks, meet compliance requirements, and optimize costs.

_Observability is a core displine of Cloud governance._

Observability involves monitoring and understanding the health and performance of systems that run in the cloud. By analyzing data such as logs, and metrics, you can identify issues and troubleshoot problems.

- Metrics are numerical data points that quantify system behavior, like CPU usage or network traffic.
- Logs are records of events that occur within the system, and provide detailed information about system activity.

In IBM Cloud, you can find the following Observability services:

- **IBM Cloud Logs**

    IBM Cloud Logs is a scalable logging service that persists logs and provides users with capabilities for querying, tailing, and visualizing logs. You can get real-time insights on IBM Cloud services, infrastructure, and applications. You can analyze logs for troubleshooting, and alerting, as well as, use the data for long-term trend analysis.

    Logs are comprised of events that are typically human-readable and have different formats, for example, unstructured text, JSON, delimiter-separated values, key-value pairs, and so on. The IBM Cloud Logs service can manage general purpose application logs, platform logs, or structured audit events. IBM Cloud Logs can be used with logs from both IBM Cloud services and customer applications, in IBM Cloud and outside IBM Cloud.


- **IBM Cloud Activity Tracker Event Routing**

    With IBM Cloud Activity Tracker Event Routing, you configure how to route auditing events in your IBM Cloud account.

    Auditing events are critical data for security operations and a key element for meeting compliance requirements.

- **IBM Cloud Logs Routing**

    With IBM Cloud Logs Routing, you configure how to route platform logs that are generated by services running in your IBM Cloud account.

- **IBM Cloud Metrics Routing**

    With IBM Cloud Metrics Routing, you configure the routing of platform metrics that are generated in your IBM Cloud account.

    Platform metrics are key to monitor the health and status of IBM Cloud services.

- **IBM Cloud Monitoring**

    IBM Cloud Monitoring is a cloud-native, and container-intelligence management system that you can include as part of your IBM Cloud architecture to gain operational visibility into the performance and health of your applications, services, and platforms. It offers administrators, DevOps teams and developers full-stack telemetry with advanced features to monitor and troubleshoot, define alerts, and design custom dashboards.

Reference information:
- [IBM Cloud Activity Tracker Event Routing](https://cloud.ibm.com/docs/atracker?topic=atracker-getting-started)
- [IBM Cloud Logs Routing](https://cloud.ibm.com/docs/logs-router?topic=logs-router-getting-started)
- [IBM Cloud Metrics Routing](https://cloud.ibm.com/docs/metrics-router?topic=metrics-router-getting-started)
- [IBM Cloud Logs](https://cloud.ibm.com/docs/cloud-logs?topic=cloud-logs-getting-started)
- [IBM Cloud Monitoring](https://cloud.ibm.com/docs/monitoring?topic=monitoring-getting-started)

## What you will learn:

- Deploy and configure IBM Cloud Observability services
- How to monitor in IBM Cloud user actions and relevant security events related to IBM Cloud VPC, IBM Power Virtual Server, and other IBM Cloud services.
- Configure a Linux hosts on a PowerVS workspace to forward logs to the IBM Cloud Logs service.
- Building dashboards, setting alerts, and automated incident response.
- Integrating third-party observability tools with IBM Cloud

## Prerequisites:

* An IBM Cloud Account with Power Virtual Server access.
* IBM Cloud CLI installed and configured / access to IBM Cloud console.
* An SSH key uploaded to your Power Virtual Server workspace.
* Familiarity with curl for making REST API calls.
* Basic understanding of JSON.
* jq installed (highly recommended for parsing JSON responses from API calls)

   `yum install jq (RHEL/CentOS) or brew install jq (macOS).`

Your IBMID must have assigned IAM policies for each of the Observability services.


## Resources that will be deployed in this HOL

In this HOL, you will deploy the following resources:

Service  | Resource Type | Name     | Notes
---------|---------------|----------|---------
Activity Tracker Event Routing | target | <TEAM_NAME>-target |
Activity Tracker Event Routing | route  | <TEAM_NAME>-route |
Metrics Routing | target | <TEAM_NAME>-target |
Metrics Routing | target | <TEAM_NAME>-route |
Logs Routing | target | |
Cloud Logs | instance | <TEAM_NAME>-cl-instance |
Monitoring | instance | <TEAM_NAME>-mon-instance |
Cloud Object Storage | bucket | <TEAM_NAME>-cl-bucket |
Event Notifications | topic | <TEAM_NAME>-topic |
Event Notifications | subscription | <TEAM_NAME>-subscription |

This document references:

- `<TEAM_NAME>` this is your team name and ID e.g. `team`

## Configure Observability in the account

### Step 1: Provision IBM Cloud Logs in the account

In IBM Cloud Logs, you can manage auditing events, and logs. Both types of data can be managed through the same instance. Auditing events are security events that have different requirements from logs, for example, you might be required to keep auditing events for 6 months or longer. Due to the differences in compliance and management requirements, logs and auditing events can be managed through different IBM Cloud Logs instances.

_Notice that for the purpose of the lab, only 1 Cloud Logs instance is used to manage logs and auditing events._

Complete the following steps to provision an instance through the UI:

1. Log in to your IBM Cloud account.
1. Click Catalog. The list of the services that are available in IBM Cloud opens.
1. To filter the list of services that is displayed, select the **Logging and Monitoring** category.
1. Click the **IBM Cloud Logs** tile.
1. Select the location where you plan to provision the instance. Choose `eu-es`
1. Enter a name for the service instance. Use <TEAM_NAME>-cl-instance
1. Select the resource group for your team <TEAM_NAME>-management-rg. By default, the Default resource group is set.
1. Select the Standard service plan.
1. Choose a retention plan. Valid values are 7 days, 14 days, 30 days, 60 days or 90 days. Choose 7 days.
1. Click Create.
After you provision an instance, the UI opens.

Reference information:
- [Provision an instance through the UI](https://cloud.ibm.com/docs/cloud-logs?topic=cloud-logs-instance-provision&interface=ui)
- [Provision an instance by using the CLI](https://cloud.ibm.com/docs/cloud-logs?topic=cloud-logs-instance-provision&interface=cli)
- [Provision an instance by using terraform](https://cloud.ibm.com/docs/cloud-logs?topic=cloud-logs-terraform-setup)

### Step 2: Configure IBM Cloud Logs in the account

_Notice that IAM authorizations between services are already defined in the account for all teams._

1. IBM Cloud Logs uses IBM Cloud Object Storage buckets to store data. You create and maintain these buckets for your IBM Cloud Logs instance.

    **Important: You should create a bucket with Cross Region resiliency to store and access data across multiple geographical regions to ensure high availability, durability, and disaster recovery capabilities. See Creating and modifying IBM Cloud Object Storage buckets.**

    The data bucket is used to store all logs that are ingested and not dropped, as well as any logs that are dropped through a block rule and marked for storage in the data bucket.

    The metrics bucket is used to store collected data usage metrics as well as metrics generated by IBM Cloud Logs.

    Complete [Configure the data bucket](https://cloud.ibm.com/docs/cloud-logs?topic=cloud-logs-configure-data-bucket) to create a data bucket and attach it to the Cloud Logs instance.

    [Configure the metrics bucket](https://cloud.ibm.com/docs/cloud-logs?topic=cloud-logs-configure-metrics-bucket) to create a metrics bucket and attach it to the Cloud Logs instance.

1. To send events that are generated when an alert is triggered in an IBM Cloud Logs instance, you must connect your IBM Cloud Logs instance to Event Notifications instance by configuring an outbound integration.

    Complete [Configure an outbound integration](https://cloud.ibm.com/docs/cloud-logs?topic=cloud-logs-event-notifications-configure) to connect IBM Cloud Logs with IBM Cloud Event Notifications.

    _Use the Event Notifications instance **observability-en**._

1. Turn off the **Severity rule**. This rule is created automatically when you provision a Cloud Logs instance. Logs and events sent to Cloud Logs through the routing services or by the agent set the severity level.

    _You will need to enable this rule for specific applications that send logs to Cloud Logs and the priority level associated with a log record is not set properly._

    1. Go to **Observability > Logging > Instances**.
    1. Identify your Cloud Logs instance and click **Dashboard**.
    1. Go to **Data Pipeline > Parsing Rules**.
    1. Turn off the rule **Severity rule**.

1. Deploy extensions to help you manage the environment.

    _IBM Cloud Logs offers a number of data extensions. Each extension contains a set of predefined items â€“ alerts, parsing rules, dashboards, saved views, actions, and more._

    1. Go to **Observability > Logging > Instances**.
    1. Identify your Cloud Logs instance and click **Dashboard**.
    1. Go to **Integrations > Extensions**.
    1. Deploy the **System Monitoring** extension. Choose *All applications* and *All subsystems*.
    1. Deploy the **Activity Tracking** extension. Choose the **ibm-audit-event* application only, and *All subsystems*.

    Explore other extensions.





### Step 3: Configure Activity Tracker Event Routing

In IBM Cloud, you can collect global events and location-based events.
- **Global events** report on activity in your account that relate to data and resources that are generally synchronized across all regions.
- **Location-based events** report on activity in your account that is generated by IBM Cloud services that are hosted within an IBM data center location, such as US-South or US-East.

Complete the following steps to configure IBM Cloud Activity Tracking to route all auditing events that are generated in the account to a central Cloud Logs instance:

1. Configure a service-to-service authorization to your IBM Cloud Logs instance.

    You must use IBM Cloud Identity and Access Management (IAM) to create an authorization that grants IBM Cloud Activity Tracker Event Routing access to IBM Cloud Logs so the IBM Cloud Activity Tracker Event Routing service can send logs to your IBM Cloud Logs instance.

    For more information, see [Creating a S2S authorization to grant access to the IBM Cloud Logs service](https://cloud.ibm.com/docs/atracker?topic=atracker-iam-service-auth-logs).

1. Create an IBM Cloud Logs target from the Observability dashboard in the IBM Cloud.

    1. Go to **Observability > Activity Tracking**.
    1. In the *Targets* section, click **Create**.
    1. Choose **Cloud Logs** for the type.
    1. Select your instance of IBM Cloud Logs under *Choose destination*.
    1. Select **Create target**.

1. Create a route to define the rules that determine where auditing events are routed in your account. For example, you can define a route that routes auditing events from 2 different regions, and also routes global events.

    1. Go to **Observability > Activity Tracking**.
    1. In the *Routes* section, click **Create**.
    1. In the *Routing rules* section, modify Rule 1: Select **All sources (wildcard)** to collect all the auditing events that are generated in the account.
    1. In the *Targets* section, choose your target.
    1. Click **Next**.
    1. Enter a name for the route <TEAM_NAME>-at-route.
    1. Click **Create**.


Reference information:
- [Managing IBM Cloud Logs targets through the UI](https://cloud.ibm.com/docs/atracker?topic=atracker-target_v2_icl&interface=ui)
- [Managing IBM Cloud Logs targets through the CLI](https://cloud.ibm.com/docs/atracker?topic=atracker-target_v2_icl&interface=cli)
- [Managing IBM Cloud Logs targets through the API](https://cloud.ibm.com/docs/atracker?topic=atracker-target_v2_icl&interface=api)
- [Managing IBM Cloud Logs targets by using terraform](https://registry.terraform.io/providers/IBM-Cloud/ibm/latest/docs/resources/atracker_target)
- [Managing IBM Cloud Logs routes through the UI](https://cloud.ibm.com/docs/atracker?topic=atracker-route_v2&interface=ui)
- [Managing IBM Cloud Logs routes through the CLI](https://cloud.ibm.com/docs/atracker?topic=atracker-route_v2&interface=cli)
- [Managing IBM Cloud Logs routes through the API](https://cloud.ibm.com/docs/atracker?topic=atracker-route_v2&interface=api)
- [Managing IBM Cloud Logs routes by using terraform](https://registry.terraform.io/providers/IBM-Cloud/ibm/latest/docs/resources/atracker_route)


### Step 4: Configure Logs Routing

Complete the following steps to configure IBM Cloud Logs Routing to route all platform logs that are generated by IBM Cloud services in the account to a central Cloud Logs instance:

1. Configure a service-to-service authorization to your IBM Cloud Logs instance.

    You must use IBM Cloud Identity and Access Management (IAM) to create an authorization that grants IBM Cloud Logs Routing access to IBM Cloud Logs so the IBM Cloud Logs Routing service can send logs to your IBM Cloud Logs instance.

    For more information, see [Creating a S2S authorization to grant access to the IBM Cloud Logs service](https://cloud.ibm.com/docs/logs-router?topic=logs-router-iam-service-auth-logs-routing&interface=ui).

1. Create a target destination per region.

    _**Notice that the IBM Cloud Logs instance must be located in the same account that you are configuring.**_

    1. Go to **Observability >Logging > Routing**.
    1. In the *Targets* section, for each region where you run operations in Cloud, click **Set target**.
    1. Select your IBM Cloud Logs instance from the list. This is the instance where you want to receive logs that are routed by IBM Cloud Logs Routing.
    1. Click Save.


Reference information:
- [Managing IBM Cloud Logs targets through the UI](https://cloud.ibm.com/docs/logs-router?topic=logs-router-tenant-create&interface=ui)
- [Managing IBM Cloud Logs targets through the API](https://cloud.ibm.com/docs/logs-router?topic=logs-router-tenant-create&interface=api)
- [Managing IBM Cloud Logs targets by using terraform](https://cloud.ibm.com/docs/logs-router?topic=logs-router-tenant-create&interface=terraform)



## Cloud Logs

In IBM Cloud Logs, you can run queries, build dashboards, alert on errors and more.  You can collect logs from a number of platforms, orchestrators, and a wide range of applications that are available in the IBM Cloud, outside the IBM Cloud, or on-prem.

Let's explore some of the features in the service:

### TCO Optimizer

In IBM Cloud Logs, you can define the way logs are distributed across different data pipelines and balance cost in your environment. For more information, see [TCO Data pipelines](https://cloud.ibm.com/docs/cloud-logs?topic=cloud-logs-tco-data-pipelines).

There are 3 data pipelines:
- Priority insights pipeline, also known as high
- Analyze and alert pipeline, also known as medium
- Store and search pipeline, also known as low

You can define policies in the Cloud Logs instance to define through which data pipeline logs are sent as they are ingested.

_**You must have an IBM Cloud Object Storage bucket configured for your Cloud Logs instance before you configure and enable TCO policies that send data through the medium and low tiers.**_

By default, all data goes through the Priority Insights data pipeline.

Policies are configured based on 3 metadata values:
- Application name: The application name is the environment that produces and sends logs to IBM Cloud Logs.
- Subsystem name: The subsystem name is the service or application that produces and sends logs to IBM Cloud Logs.
- Severity
For more information, see [Metadata](https://cloud.ibm.com/docs/cloud-logs?topic=cloud-logs-metadata).

Complete the following steps to create a policy that sends all data through the medium tier at ingestion:
1. Go to **Observability > Logging > Instances**.
1. Identify your Cloud Logs instance and click **Dashboard**.
1. Go to **Data Pipeline > TCO Optimizer**.
1. Click ADD NEW POLICY.
1. Enter a policy name, for example **Move all logs to Analyze and Alert**.
1. Enter the policy details with the relevant applications, subsystems, and severity. Add more criteria as needed. For this exercise, choose **All** applications, **All** subsystems, and **All** severities.

    For applications and subsystems, criteria can be specified when the value matches one of: All, Is, Is Not, Includes, or Starts With.

1. Set the priority for the policy. The priority determines the pipeline for logs that are matched by the policy. Choose **Medium**.
1. Click APPLY.

_TIP: When you are troubleshooting problems, go to the TCO Optimizer to understand through which pipeline logs from an application are processed._

### Views

In IBM Cloud Logs, you can configure views to see logs that match a specific filtering criteria.
- Views can be shared (public) or private.
- To configure a custom view, you can define a query, filter by selected fields, or both.
- Views can be grouped into folders. The folder order cannot be changed.
- View names must be unique within a folder.
- You can use [Lucene](https://cloud.ibm.com/docs/cloud-logs?topic=cloud-logs-query-data-lucene), [Regex](https://cloud.ibm.com/docs/cloud-logs?topic=cloud-logs-query-regex) or [Dataprime](https://cloud.ibm.com/docs/cloud-logs?topic=cloud-logs-query-data-dataprime) to query the data in a view.
For more information, see [Managing custom views in IBM Cloud Logs](https://cloud.ibm.com/docs/cloud-logs?topic=cloud-logs-custom_views).

Complete the following steps to create a view:
1. Go to **Observability > Logging > Instances**.
1. Identify your Cloud Logs instance and click **Dashboard**.
1. Click **Explore Logs > Logs**.
1. Select the fields to be included in the view. By default you can select Applications, Subsystems, and log Severities.
1. (Optional) Add additional filters click **+ Add Filter** and select and configure additional field and filter values.
1. Select if you want you view to only include Priority Logs (those in the Priority insights pipeline) or All Logs, that is, logs that are stored in IBM Cloud Object Storage.

    Logs in IBM Cloud Object Storage includes logs collected through all the data pipelines.

1. (Optional) Add a Lucene or DataPrime query to further filter your data.

    Add the Lucene query **_exists_:"action"**

1. Specify the time interval for the view, for example Last 2 Days.
1. Save your view by clicking the three dots ...

    Enter a name for your view.
    If you want to save the query and filter values you configured, check Save query and filters.
    If you want your view to be the default view, check Set as default view. This sets the view as the default for you as the user. It does not set the view as the default view for the entire account.
    Set the privacy of your view. Private views can only be seen by you. You can set a view as Private or Shared.

1. Click **Create**.

### Dashboards

In IBM Cloud Logs, you can use dashboards to monitor related data through different types of data visualizations, also known as widgets.
- Custom dashboard are comprised of widgets.
- You can add one or more widgets to a dashboard.
- Each widget supports different data types: logs or metrics.
- The timeframe configured for the dashboard is applied to all the widgets. Alternatively, you can select a different time range per widget.
- Widgets can display data from Priority Insights by selecting **Priority Insights**, or from Priority Insights and Analyze and Alert by selecting **Analyze and Alert**.

Dashboards can include one or more of the following visualizations:
- Data table
- Line chart
- Gauge
- Pie chart
- Vertical bar chart
- Horizontal bar chart
- Markdown
- DataPrime creator

For more information, see [Dashboards](https://cloud.ibm.com/docs/cloud-logs?topic=cloud-logs-about_dashboards) and [Creating a dashboard](https://cloud.ibm.com/docs/cloud-logs?topic=cloud-logs-create_dashboards).

Complete the following steps to import a dashboard:
1. Go to **Observability > Logging > Instances**.
1. Identify your Cloud Logs instance and click **Dashboard**.
1. Go to **Dashboards > Custom Dashboards**.
1. Click **New > Import dashboard**.
1. Select [secrets_manager_06-07-2025.json](resources/HOL6/secrets_manager_06-07-2025.json) file from your system.
1. Click **Import**.

### Parsing rules

In IBM Cloud Logs, you can use parsing rules to process, parse, and restructure log data to prepare for monitoring and analysis. For example, you can extract selected information, structure unstructured logs, or discard unnecessary parts of the logs. You can mask fields for compliance reasons and fix misformatted logs. You can block log data from being ingested based on log content and much more.

You can configure the following parsing rules:
- **Parse** parsing rule: Convert unstructured text into JSON format.
- **Extract** parsing rule: Extract values as JSON keys without parsing the entire log.
- **JSON Extract** parsing rule icon: Extract the value of a JSON key into a metadata field.
- **Replace** parsing rule icon: Replace the value of a field with a fixed string value to fix the log structure, change the log severity, or obfuscate information.
- **Block** parsing rule icon: Drop incoming logs by using a regex expression.
- **Timestamp Extract** parsing rule icon: Replace the log timestamp with a timestamp that is included in the log.
- **Remove Fields** parsing rule icon: Remove JSON fields in a log to reduce the number of indexed fields.
- **STRINGIFY JSON FIELD** parsing rule icon: Transform a JSON field into a stringify JSON field to reduce the number of indexed fields.
- **PARSE JSON FIELD** parsing rule icon: Transform escaped or stringified fields into JSON format.

For more information, see [Parsing rules](https://cloud.ibm.com/docs/cloud-logs?topic=cloud-logs-log_parsing_rules).

Review the parsing rule **Severity Rule**.

### Alerts

IBM Cloud Logs, alerts allow for timely detection of anomalies, proactive incident response, improved mean time to resolution (MTTR), reduced manual monitoring effort, customization, and flexibility. Powered by machine learning, alerting proactively notifies teams of potential problems, correlates incidents, and provides root cause analysis.

You can configure the following types of alerts:
- Standard alerts
- Time relative alerts
- Unique count alerts
- Ratio alerts
- New value alerts
- Flow alerts

For more information, see [Alerts](https://cloud.ibm.com/docs/cloud-logs?topic=cloud-logs-alerts).

Later in the lab, you will configure an alert.

### Event to metrics

In IBM Cloud Logs, you can generate metrics from Priority insights logs and Analyze and alert logs.

_**You must have a metrics bucket configured for your IBM Cloud Logs instance.**_

When you define metrics from logs, consider the following information:
- Metrics are collected from the point in time in which they were defined.
- You can create up to 30 metric rules.
- You can set the retention period to any length. You manage the metrics bucket and you can retain the data for as long as you need.
- You have a quota of 10M total metric permutations per day.
- Your maximum query time range for your Events2Metrics indices is 90 days.

For more information, see [Configuring collection of metrics from logs](https://cloud.ibm.com/docs/cloud-logs?topic=cloud-logs-configure-event2metrics).


## IBM Cloud VPC

A virtual private cloud (VPC) is a secure, isolated virtual network that combines the security of a private cloud with the availability and scalability of IBM's public cloud.

VPC generates the following platform telemetry data:

- Activity Tracking events that you can use to monitor and report VPC activity in your account. For more information, see [Activity tracking events for IBM Cloud VPC](https://cloud.ibm.com/docs/vpc?topic=vpc-at_events&interface=ui)

- Platform logs that you can use to investigate abnormal activity and critical actions in your account, and troubleshoot problems. For more information, see [Logging for VPC](https://cloud.ibm.com/docs/vpc?topic=vpc-logging&interface=ui)


You can use IBM Cloud Logs to visualize and alert on platform data that is generated in your account.


### Monitoring Activity Tracking events

You can use IBM Cloud Logs to monitor and alert on events that are generated in your account by any of the following VPC resources:

- ACL events
- Cluster network events
- DNS resolution binding events
- Floating IP events
- Flow log events
- Load balancer events
- Private Path service events
- Public gateway events
- Reservations
- Reserved IPs
- Routing table events
- Security group events
- Subnet events
- Virtual network interface events
- Virtual network interface target resource events
- Virtual private endpoint events
- VPC events
- VPN gateway events
- VPN server events

These components generate events for CRUD actions, and attach and detach actions. After you configure IBM Cloud Activity Tracking Event Routing, the events are routed by IBM Cloud Activity Tracker Event Routing to your IBM Cloud Logs instance.

In IBM Cloud Logs, you can run queries, build dashboards, alert on the errors based on information included in these events.

Complete the following steps to create custom views to monitor your VPC infrastructure:
1. Go to **Observability > Logging > Instances**.
1. Identify your Cloud Logs instance and click **Dashboard**.
1. Click **Explore Logs > Logs**.
1. Create and save the following views and explore the options to customize the view by adding columns for example:

    Lucene query to identify unauthorized access to VPC resources: `reason.reasonCode:("403" OR "401")`  Name view: `<TEAM_NAME> unauthorized access`

    Dataprime query to list all the VPC resources that are provisioned in the last 2 days: `source logs | filter action.contains('create') | countby serviceName,action into request_count` Name view: <TEAM_NAME> Instances created by service

    Dataprime query to list all the VPC resources that are deleted in the last 2 days: `source logs | filter action.contains('delete') | countby serviceName,action into request_count` Name view: <TEAM_NAME> Instances deleted by service

    Dataprime query to add the size of each log: `source logs | create size_d from length($d:string) | create size_m from length($m:string) | create size_l from length($l:string) | create total_size from size_d+size_l+size_m` Name view: <TEAM_NAME> Add size to log record

    Dataprime query to add metadata to log records: `source logs | add metadata from $m` Name view: <TEAM_NAME> Add metadata to log record

    Lucene query to list VPC instances that are started: `action:"is.instance.instance.start" Name view: <TEAM_NAME> VSIs started

    Lucene query to list VPC instances that are stopped: `action:"is.instance.instance.stop" Name view: <TEAM_NAME> VSIs stopped

    Use the list of events in [VPC events](https://cloud.ibm.com/docs/vpc?topic=vpc-at_events&interface=ui#events-network) and add a query to monitor when a network ACL is created or deleted.

### Monitoring Platform logs

In IBM Cloud Logs, you can monitor [Log messages](https://cloud.ibm.com/docs/vpc?topic=vpc-logging&interface=ui#logging_msgs) generated by some VPC components.

For example, you can monitor these messages that are generted by the Load Balancer for VPC service:

| Message Category | Type | Description |
|----------|-------|------|
| Health check	| info	| Connect from <IP>:<PORT> to <IP>:<PORT> |
| Connect |	info	| Health check for server <ID>> failed, reason: Layer4 connection problem, info: "General socket error (Network is unreachable)", check duration: 0ms, status: 1/2 UP |

Try the following queries to filter for this logs:

Query 1: `message.message:"Connect from"`
Query 2: `message.message:("Health check for server" AND "failed" AND "Layer4 connection problem")`



## Activity Tracking events generated by the IBM Power Virtual Server service

IBM Power Virtual Server generates Activity Tracking events that you can use to monitor and report PowerVS activity in your account. For more information, see [Activity Tracking events for IBM Power Virtual Server](https://cloud.ibm.com/docs/power-iaas?topic=power-iaas-at-events)


Generate some events in your account by running the following CLI commands:

ibmcloud pi instance action b455235a-d7bd-408f-9bf9-a81b431e03f5 --operation start
ibmcloud pi instance action b455235a-d7bd-408f-9bf9-a81b431e03f5 --operation stop
ibmcloud pi instance action b455235a-d7bd-408f-9bf9-a81b431e03f5 --operation soft-reboot
ibmcloud pi instance action b455235a-d7bd-408f-9bf9-a81b431e03f5 --operation hard-reboot


### Create custom views

Complete the following steps to create custom views to monitor your VPC infrastructure:
1. Go to **Observability > Logging > Instances**.
1. Identify your Cloud Logs instance and click **Dashboard**.
1. Click **Explore Logs > Logs**.
1. In *subsystem*, select **power-iass:<TEAMID-WorkspaceID>**
1. Save the view. Name it **PowerVS events**
1. Create a folder **PowerVS** and move your view to this folder.
1. Create and save the following views and explore the options to customize the view by adding columns for example:

    Lucene query to list all the actions on an instance: `_exists_:"requestData.action"`  Name view: `PowerVS instance actions`

    Lucene query to list all the events generated when an instance is started: `requestData.action:"start"`  Name view: `PowerVS instance started`

    Lucene query to list all the events generated when an instance is stopped: `requestData.action:"stop""`  Name view: `PowerVS instance stopped`

    Lucene query to list all the events generated when an instance gets a soft-reboot: `action:"power-iaas.pvm-instance.renew" AND requestData.action:"soft\-reboot"`  Name view: `PowerVS soft-rebbot`

    Lucene query to list all the events generated when an instance gets a hard-reboot: `action:"power-iaas.pvm-instance.renew" AND requestData.action:"hard\-reboot"`  Name view: `PowerVS hard-reboot`

### Create a parsing rule

Complete the following steps to create a parsing rule that extracts the PowerVS instance ID:
1. Go to **Observability > Logging > Instances**.
1. Identify your Cloud Logs instance and click **Dashboard**.
1. Click **Data pipeline > Parsing rules**.
1. Select **Create rule group** Then, enter the following details:

    Rule group name: **PowerVS**
    Rule Matcher Applications: **ibm-audit-event**
    Rule matcher subsystems: Choose your **power-iass:<TEAMID-WorkspaceID>**
    Severity: **Info**

1. Select the **Extract** rule. Then, enter the following details:

    name: **Instance ID**
    Source Field: **Text.message**
    Regular expression: `pvm-instance.*/(?P<pwInstanceID>.*)`

1. Click **Create rule group**

After you create the parsing rule, generate a few more events.



### Create a dashboard

Complete the following steps to create a dashboard:
1. Go to **Observability > Logging > Instances**.
1. Identify your Cloud Logs instance and click **Dashboard**.
1. Click **Dashboards > Custom dashboards**.
1. In *Add new*, click **New > Create new dashboard**
1. Name the dashboard **PowerVS Overview**.
1. Click the `+` symbol to add widgets. Add a **Section**. Name the section **Actions**
1. Click the manage filters icon (funnel), and click **+Filter**. Select the field **subsystem**. Select your `power-iass:<workspaceID>`

    Add the field **pwInstanceID** as a filter to the dashboard.

1. Add a **Gauge** to display the total number of events generated by your PowerVS workspace and configure it as follows:

    Select **Logs > Analyze and Alert**
    In the *Functions* group by **subsystem** and *Agg* as **count**
    Click **Save**

1. Add another **Gauge** to display the events for all the actions on an instance.

    Select **Logs > Analyze and Alert**
    Enter the Lucene query `_exists_:"requestData.action"`
    In the *Functions* group by **requestData.action** and *Agg* as **count**
    Click **Save**

    Check how different gauges are added for each action identified.

1. Add a **Table**

    Select **Logs > Analyze and Alert**
    Enter the Lucene query `_exists_:"requestData.action"`
    In the *Manage columns*, add the following columns: Subsystem, pwInstanceID, requestData.action, message
    Click **Save**


Explore other widgets. Try adding a widget to show all stop requests only.


### Create an alert

Complete the following steps to create an alert:
1. Go to **Observability > Logging > Instances**.
1. Identify your Cloud Logs instance and click **Dashboard**.
1. Click **Alerts > Alert Management > New alert**.
1. Enter the following details:

    Name: **VSI rebooted**
    Alert severity: **Warning**
    Labels: **team:sre**
    Alert type: **Standard**
    Query: `reason.reasonCode.numeric:[400 TO 500]`
    Applications: **ibm-audit-event**
    Subsystem: **power-iass:<TEAMID-WorkspaceID>**
    Severities: Clicl **All**
    Condition: **More than usual**
    Minimum threshold: 0
    Time Window: 5 minutes
    Group by: **coralogix.metadata.subsystemName** and **pwInstanceID**
    Notification content: Add the fields: `pwInstanceID`, `requestData.action`, `message`, `reason.reasonCode`, `reason.reasonForFailure`

1. Click **Create**.

    _Note that takes about 15 minutes for alert definitions to be enabled._

After you wait, run the CLI command 3 times  fast to generate an error trying to restart:
`ibmcloud pi instance action <your PW VSI Instance ID> --operation hard-reboot`

Check the Incidents page to see that the alert has triggered. Check out the alert history.


## Configure a PowerVS instance to send logs to the Cloud Logs instance

To send logs from a PowerVS host, you must configure Rsyslog. You also need a Linux server running the logging agent.


1. Configure the logging agent in the VPC VSI that you created in HOL1.

#### Step 1: Configure a trusted profile:

1. In the IBM Cloud console, click **Manage > Access (IAM) > Trusted profiles**. Then, click **Create profile**.
1. Describe your profile by providing a name `<TEAMNAME>-power-tp` and a description. Then, click Continue.
1. In *Select trusted entity type*, select **Compute resources**.
1. In *Create trust relationship*, select **Virtual server for VPC**.
1. Select **Specific resources** and choose your VPC VSI.
1. Click **Continue**.
1. In *Assign access*, select **Access policy**.
1. Create a policy.

    Service: **Cloud Logs**
    Resources: All resources
    Roles and actions: **Sender**

    _**Important: Make sure the user who grants the policy has the Sender role permissions.**_

1. Click **Create**.

#### Step 2: Install the agent on the VPC VSI

Complete the follwoing steps:

1. Download the agent 1.6.0. See release notes for more information on [Logging agent version 1.6.0](https://cloud.ibm.com/docs/cloud-logs?topic=cloud-logs-release-notes-agent)

    `yum install wget`
    `wget https://logs-router-agent-install-packages.s3.us.cloud-object-storage.appdomain.cloud/logs-router-agent-ubuntu20-1.6.0.deb`
    `wget https://logs-router-agent-install-packages.s3.us.cloud-object-storage.appdomain.cloud/logs-router-agent-ubuntu20-1.6.0.deb.sha256`

    Validate the checksum by running the following command:

    `sha256sum -c  logs-router-agent-ubuntu20-1.6.0.deb.sha256`

1. Run the following: It is needed to deploy the agent in the version of Ubuntu that you are using for the VSI:

    `sudo apt-get install libssl-dev`
    `sudo apt-get install openssl`
    `wget http://nz2.archive.ubuntu.com/ubuntu/pool/main/o/openssl/libssl1.1_1.1.1f-1ubuntu2_amd64.deb`
    `sudo dpkg -i libssl1.1_1.1.1f-1ubuntu2_amd64.deb`

1. Install the agent package by running:

    `dpkg -i logs-router-agent-ubuntu20-1.6.0.deb`

1. Download the configuration file.

    `wget https://logs-router-agent-config.s3.us.cloud-object-storage.appdomain.cloud/post-config.sh`

    `chmod +777 post-config.sh`

1. Run the configuration script.

    `./post-config.sh -h <YOUR_CLOUD_LOGS_ID>.ingress.<CL_REGION>>.logs.cloud.ibm.com -p 443 -t /logs/v1/singles -a VSITrustedProfile -d Profile-<TP_ID> --send-directly-to-icl`

1. Add additional metadata fields. Edit the fluent-bit.conf file in the **/etc/fluent-bit/** folder.

    Add your custom metadata using this structure: Add <meta.key_name> <your_custom_value>

    ```
    [FILTER]
    Name modify
    Match *
    Add subsystemName subsystemName
    Add applicationName applicationName
    Add meta.hostname ${HOSTNAME}
    Add meta.environment prod   # Sample values: prod, staging, dev, qa
    Add meta.platform linux

    [FILTER]
    Name nest
    Match *
    Operation nest
    Wildcard meta.*
    Nest_under meta
    Remove_prefix meta.
    ```

    For example, set subsystemName to **powervs-collector**

    Save the configuration file.

1. Restart the agent to apply the changes.

    `systemctl daemon-reload && systemctl restart fluent-bit`

1. Check if you have any errors

    `sudo apt-get install systemd`
    `journalctl -u fluent-bit -> to get errors`

1. Check the status of the agent

    `systemctl status fluent-bit`

#### Step 3: Configure the agent to collect syslog data

1. Edit the fluent-bit.conf file in the **/etc/fluent-bit/** folder.
1. To listen for Syslog messages on the Network mode over TCP, add:

    [INPUT]
    Name     syslog
    Parser   syslog-rfc3164
    Listen   0.0.0.0
    Port     5140
    Mode     tcp

1. Restart the agent

    `systemctl daemon-reload && systemctl restart fluent-bit`

#### Step 4:Configure Rsyslog in your PowerVS instance

Complete the following steps:

1. Add a new entry to the rsyslog config file and add the following:

    `action(type="omfwd" Target="VSI_IP" Port="5140" Protocol="tcp")`

    Modify the file. Uncomment the following lines:
    `#module(load="imudp")`
    `#input(type="imudp" port="514")`

    `#module(load="imtcp")`
    `#input(type="imtcp" port="514")`

1. Restart your rsyslog daemon:

    `sudo service rsyslog restart`

1. Check the status

    `systemctl status rsyslog`



## Sending notifications through IBM Cloud Event Notifications

You can configure alert in IBM Cloud Logs and IBM Cloud Monitoring that send notifications through IBM Clooud Event Notifications to different types of destinations.

Complete the following steps to configure alert notifications to be triggered through Event Notifications:
- [Configure alerts in IBM Cloud Monitoring that send email notifications](https://cloud.ibm.com/docs/monitoring?topic=monitoring-tutorial-en)
- [Configuring alerts in IBM Cloud Logs](https://cloud.ibm.com/docs/cloud-logs?topic=cloud-logs-alerts-config)


## Integrating third-party observability tools with IBM Cloud Observability services

You can integrate IBM Cloud Logs and IBM Cloud Monitoring with other third party observability tools by streaming data to IBM Cloud Event Streams.

Complete the following steps to configure streaming:

- [Integrating IBM Cloud Logs with Event Streams](https://cloud.ibm.com/docs/cloud-logs?topic=cloud-logs-streaming-config)
- [Streaming metrics to a Kafka service](https://cloud.ibm.com/docs/monitoring?topic=monitoring-data_streaming)


## Questions

1. What is the role of each Observability service?
2. What are the advantages and disadvantages of configuring a central architecture compared with a distributed architecture?
3. What services and features can you configure to detect spikes of logs promptly? And new errors? or new values of a specific field?
4. Can you outline the tasks and resources that you must configure to trigger an email alert? In Cloud Logs and in Monitoring.
5. Where do you monitor the alerts that are triggered? In Cloud Logs and in Monitoring.
6. Can you add data and enrich a log record?
7. When would you use the extract parsing rule? and the block rule?
8. When should you configure a logging agent?
9. How many query languages can you use to search data in Cloud Logs?
